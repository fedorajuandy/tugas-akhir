{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNXIo_Q34ohv"
      },
      "source": [
        "# Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YZRxF815bxH",
        "outputId": "d787bee3-aad0-4617-e419-17a3e31e743b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ai-benchmark\n",
            "  Downloading ai_benchmark-0.1.2-py3-none-any.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (1.23.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (9.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (67.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ai-benchmark) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ai-benchmark) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ai-benchmark) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ai-benchmark) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ai-benchmark) (2023.7.22)\n",
            "Installing collected packages: ai-benchmark\n",
            "Successfully installed ai-benchmark-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ai-benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B7HqFxj4l53",
        "outputId": "ecd748f1-59ee-4256-ccea-f4122267860e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>   AI-Benchmark-v.0.1.2   \n",
            ">>   Let the AI Games begin..\n",
            "\n",
            "*  TF Version: 2.8.2\n",
            "*  Platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "*  CPU: N/A\n",
            "*  CPU RAM: 13 GB\n",
            "\n",
            "The benchmark is running...\n",
            "The tests might take up to 20 minutes\n",
            "Please don't interrupt the script\n",
            "\n",
            "1/19. MobileNet-V2\n",
            "\n",
            "1.1 - inference | batch=50, size=224x224: 1429 ± 411 ms\n",
            "1.2 - training  | batch=50, size=224x224: 6215 ± 44 ms\n",
            "\n",
            "2/19. Inception-V3\n",
            "\n",
            "2.1 - inference | batch=20, size=346x346: 5274 ± 298 ms\n",
            "2.2 - training  | batch=20, size=346x346: 23244 ± 1638 ms\n",
            "\n",
            "3/19. Inception-V4\n",
            "\n",
            "3.1 - inference | batch=10, size=346x346: 5406 ± 14 ms\n",
            "3.2 - training  | batch=10, size=346x346: 22680 ± 633 ms\n",
            "\n",
            "4/19. Inception-ResNet-V2\n",
            "\n",
            "4.1 - inference | batch=10, size=346x346: 5928 ± 12 ms\n",
            "4.2 - training  | batch=8, size=346x346: 19812 ± 178 ms\n",
            "\n",
            "5/19. ResNet-V2-50\n",
            "\n",
            "5.1 - inference | batch=10, size=346x346: 3146 ± 15 ms\n",
            "5.2 - training  | batch=10, size=346x346: 12844 ± 572 ms\n",
            "\n",
            "6/19. ResNet-V2-152\n",
            "\n",
            "6.1 - inference | batch=10, size=256x256: 5050 ± 20 ms\n",
            "6.2 - training  | batch=10, size=256x256: 22649 ± 1565 ms\n",
            "\n",
            "7/19. VGG-16\n",
            "\n",
            "7.1 - inference | batch=20, size=224x224: 10136 ± 18 ms\n",
            "7.2 - training  | batch=2, size=224x224: 5697 ± 352 ms\n",
            "\n",
            "8/19. SRCNN 9-5-5\n",
            "\n",
            "8.1 - inference | batch=10, size=512x512: 9276 ± 560 ms\n",
            "8.2 - inference | batch=1, size=1536x1536: 8584 ± 593 ms\n",
            "8.3 - training  | batch=10, size=512x512: 45604 ± 84 ms\n",
            "\n",
            "9/19. VGG-19 Super-Res\n",
            "\n",
            "9.1 - inference | batch=10, size=256x256: 16947 ± 1138 ms\n",
            "9.2 - inference | batch=1, size=1024x1024: 26280 ± 613 ms\n",
            "9.3 - training  | batch=10, size=224x224: 57817.0 ± 0.0 ms\n",
            "\n",
            "10/19. ResNet-SRGAN\n",
            "\n",
            "10.1 - inference | batch=10, size=512x512: 12356 ± 43 ms\n",
            "10.2 - inference | batch=1, size=1536x1536: 11437 ± 551 ms\n",
            "10.3 - training  | batch=5, size=512x512: 23229 ± 663 ms\n",
            "\n",
            "11/19. ResNet-DPED\n",
            "\n",
            "11.1 - inference | batch=10, size=256x256: 14004 ± 545 ms\n",
            "11.2 - inference | batch=1, size=1024x1024: 22826 ± 492 ms\n",
            "11.3 - training  | batch=15, size=128x128: 23864 ± 866 ms\n",
            "\n",
            "12/19. U-Net\n",
            "\n",
            "12.1 - inference | batch=4, size=512x512: 30789 ± 1300 ms\n",
            "12.2 - inference | batch=1, size=1024x1024: 29222 ± 622 ms\n",
            "12.3 - training  | batch=4, size=256x256: 27029 ± 647 ms\n",
            "\n",
            "13/19. Nvidia-SPADE\n",
            "\n",
            "13.1 - inference | batch=5, size=128x128: 13109 ± 1125 ms\n",
            "13.2 - training  | batch=1, size=128x128: 10875 ± 77 ms\n",
            "\n",
            "14/19. ICNet\n",
            "\n",
            "14.1 - inference | batch=5, size=1024x1536: 5252 ± 21 ms\n",
            "14.2 - training  | batch=10, size=1024x1536: 12367 ± 627 ms\n",
            "\n",
            "15/19. PSPNet\n",
            "\n",
            "15.1 - inference | batch=5, size=720x720: 63916.0 ± 0.0 ms\n",
            "15.2 - training  | batch=1, size=512x512: 22832 ± 596 ms\n",
            "\n",
            "16/19. DeepLab\n",
            "\n",
            "16.1 - inference | batch=2, size=512x512: 13310 ± 919 ms\n",
            "16.2 - training  | batch=1, size=384x384: 14526 ± 506 ms\n",
            "\n",
            "17/19. Pixel-RNN\n",
            "\n",
            "17.1 - inference | batch=50, size=64x64: 4915 ± 56 ms\n",
            "17.2 - training  | batch=10, size=64x64: 3766 ± 21 ms\n",
            "\n",
            "18/19. LSTM-Sentiment\n",
            "\n",
            "18.1 - inference | batch=100, size=1024x300: 23113 ± 538 ms\n",
            "18.2 - training  | batch=10, size=1024x300: 48644 ± 872 ms\n",
            "\n",
            "19/19. GNMT-Translation\n",
            "\n",
            "19.1 - inference | batch=1, size=1x20: 2514 ± 65 ms\n",
            "\n",
            "Device Inference Score: 141\n",
            "Device Training Score: 166\n",
            "Device AI Score: 307\n",
            "\n",
            "For more information and results, please visit http://ai-benchmark.com/alpha\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CPU\n",
        "\n",
        "from ai_benchmark import AIBenchmark\n",
        "results = AIBenchmark().run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI270IOOb42H",
        "outputId": "80e9c429-9d9a-466b-a0c4-5247fe2b1db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>   AI-Benchmark-v.0.1.2   \n",
            ">>   Let the AI Games begin..\n",
            "\n",
            "*  TF Version: 2.12.0\n",
            "*  Platform: Linux-5.15.109+-x86_64-with-glibc2.35\n",
            "*  CPU: N/A\n",
            "*  CPU RAM: 13 GB\n",
            "*  GPU/0: Tesla T4\n",
            "*  GPU RAM: 13.3 GB\n",
            "*  CUDA Version: 11.8\n",
            "*  CUDA Build: V11.8.89\n",
            "\n",
            "The benchmark is running...\n",
            "The tests might take up to 20 minutes\n",
            "Please don't interrupt the script\n",
            "\n",
            "1/19. MobileNet-V2\n",
            "\n",
            "1.1 - inference | batch=50, size=224x224: 67.7 ± 7.3 ms\n",
            "1.2 - training  | batch=50, size=224x224: 206 ± 3 ms\n",
            "\n",
            "2/19. Inception-V3\n",
            "\n",
            "2.1 - inference | batch=20, size=346x346: 96.0 ± 3.3 ms\n",
            "2.2 - training  | batch=20, size=346x346: 337 ± 2 ms\n",
            "\n",
            "3/19. Inception-V4\n",
            "\n",
            "3.1 - inference | batch=10, size=346x346: 95.4 ± 2.1 ms\n",
            "3.2 - training  | batch=10, size=346x346: 355 ± 2 ms\n",
            "\n",
            "4/19. Inception-ResNet-V2\n",
            "\n",
            "4.1 - inference | batch=10, size=346x346: 131 ± 1 ms\n",
            "4.2 - training  | batch=8, size=346x346: 368 ± 4 ms\n",
            "\n",
            "5/19. ResNet-V2-50\n",
            "\n",
            "5.1 - inference | batch=10, size=346x346: 62.5 ± 0.7 ms\n",
            "5.2 - training  | batch=10, size=346x346: 210 ± 1 ms\n",
            "\n",
            "6/19. ResNet-V2-152\n",
            "\n",
            "6.1 - inference | batch=10, size=256x256: 89.4 ± 3.7 ms\n",
            "6.2 - training  | batch=10, size=256x256: 287 ± 3 ms\n",
            "\n",
            "7/19. VGG-16\n",
            "\n",
            "7.1 - inference | batch=20, size=224x224: 147 ± 2 ms\n",
            "7.2 - training  | batch=2, size=224x224: 230 ± 2 ms\n",
            "\n",
            "8/19. SRCNN 9-5-5\n",
            "\n",
            "8.1 - inference | batch=10, size=512x512: 128 ± 3 ms\n",
            "8.2 - inference | batch=1, size=1536x1536: 139 ± 2 ms\n",
            "8.3 - training  | batch=10, size=512x512: 370 ± 3 ms\n",
            "\n",
            "9/19. VGG-19 Super-Res\n",
            "\n",
            "9.1 - inference | batch=10, size=256x256: 159.6 ± 1.0 ms\n",
            "9.2 - inference | batch=1, size=1024x1024: 267 ± 2 ms\n",
            "9.3 - training  | batch=10, size=224x224: 510 ± 5 ms\n",
            "\n",
            "10/19. ResNet-SRGAN\n",
            "\n",
            "10.1 - inference | batch=10, size=512x512: 219 ± 2 ms\n",
            "10.2 - inference | batch=1, size=1536x1536: 188 ± 2 ms\n",
            "10.3 - training  | batch=5, size=512x512: 290 ± 2 ms\n",
            "\n",
            "11/19. ResNet-DPED\n",
            "\n",
            "11.1 - inference | batch=10, size=256x256: 225 ± 2 ms\n",
            "11.2 - inference | batch=1, size=1024x1024: 365 ± 1 ms\n",
            "11.3 - training  | batch=15, size=128x128: 335 ± 1 ms\n",
            "\n",
            "12/19. U-Net\n",
            "\n",
            "12.1 - inference | batch=4, size=512x512: 464 ± 3 ms\n",
            "12.2 - inference | batch=1, size=1024x1024: 448 ± 3 ms\n",
            "12.3 - training  | batch=4, size=256x256: 414 ± 2 ms\n",
            "\n",
            "13/19. Nvidia-SPADE\n",
            "\n",
            "13.1 - inference | batch=5, size=128x128: 180 ± 1 ms\n",
            "13.2 - training  | batch=1, size=128x128: 262 ± 2 ms\n",
            "\n",
            "14/19. ICNet\n",
            "\n",
            "14.1 - inference | batch=5, size=1024x1536: 241 ± 8 ms\n",
            "14.2 - training  | batch=10, size=1024x1536: 740 ± 34 ms\n",
            "\n",
            "15/19. PSPNet\n",
            "\n",
            "15.1 - inference | batch=5, size=720x720: 931 ± 35 ms\n",
            "15.2 - training  | batch=1, size=512x512: 287 ± 2 ms\n",
            "\n",
            "16/19. DeepLab\n",
            "\n",
            "16.1 - inference | batch=2, size=512x512: 224 ± 2 ms\n",
            "16.2 - training  | batch=1, size=384x384: 219.7 ± 1.0 ms\n",
            "\n",
            "17/19. Pixel-RNN\n",
            "\n",
            "17.1 - inference | batch=50, size=64x64: 933 ± 143 ms\n",
            "17.2 - training  | batch=10, size=64x64: 4234 ± 595 ms\n",
            "\n",
            "18/19. LSTM-Sentiment\n",
            "\n",
            "18.1 - inference | batch=100, size=1024x300: 785 ± 50 ms\n",
            "18.2 - training  | batch=10, size=1024x300: 1973 ± 284 ms\n",
            "\n",
            "19/19. GNMT-Translation\n",
            "\n",
            "19.1 - inference | batch=1, size=1x20: 228 ± 28 ms\n",
            "\n",
            "Device Inference Score: 6703\n",
            "Device Training Score: 7288\n",
            "Device AI Score: 13991\n",
            "\n",
            "For more information and results, please visit http://ai-benchmark.com/alpha\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GPU Tesla T4 x 1\n",
        "\n",
        "from ai_benchmark import AIBenchmark\n",
        "results = AIBenchmark().run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
